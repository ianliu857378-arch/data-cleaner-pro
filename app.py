"""
Advanced Data Refinery - OpenRefineå‡çº§ç‰ˆ
ä¸€ä¸ªæ¯”OpenRefineæ›´å…ˆè¿›çš„æ•°æ®æ¸…æ´—å·¥å…·ï¼Œæ”¯æŒï¼š
1. AIè‡ªåŠ¨å­—æ®µç±»å‹è¯†åˆ«
2. å¤šæ ¼å¼æ—¥æœŸæ¸…æ´—ï¼ˆå«æ­§ä¹‰æ£€æµ‹ï¼‰
3. æ•°å€¼èŒƒå›´å¼‚å¸¸æ£€æµ‹ï¼ˆä¿ç•™åŸå§‹å€¼ï¼‰
4. å¯è§†åŒ–å¼‚å¸¸é¢æ¿
5. ç»“æ„åŒ–æ¸…æ´—æ—¥å¿—ï¼ˆJSONå¯¼å‡ºï¼‰
"""

import streamlit as st
import pandas as pd
import numpy as np
import json
import io
from datetime import datetime
import re
from pathlib import Path



# ========== Page Config ==========
st.set_page_config(
    page_title="Advanced Data Refinery",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========== Custom CSS ==========
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');

    .stApp {
        background: linear-gradient(135deg, #f8fafc 0%, #e0f2fe 50%, #f8fafc 100%);
        font-family: 'Inter', sans-serif;
    }

    /* Hero Section */
    .hero-banner {
        background: linear-gradient(135deg, #1e40af 0%, #3b82f6 50%, #2563eb 100%);
        padding: 2rem;
        border-radius: 16px;
        color: white;
        margin-bottom: 2rem;
        box-shadow: 0 10px 25px -5px rgba(59, 130, 246, 0.4);
    }

    .hero-title {
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
    }

    .hero-subtitle {
        font-size: 1.1rem;
        opacity: 0.9;
    }

    /* Stats Cards */
    .stat-card {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        border-left: 4px solid #3b82f6;
    }

    .stat-value {
        font-size: 2rem;
        font-weight: 700;
        color: #1e293b;
    }

    .stat-label {
        font-size: 0.875rem;
        color: #64748b;
        text-transform: uppercase;
        letter-spacing: 0.05em;
    }

    /* Issue Badges */
    .issue-badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 9999px;
        font-size: 0.75rem;
        font-weight: 600;
        margin-right: 0.5rem;
    }

    .issue-out_of_range {
        background-color: #fef2f2;
        color: #dc2626;
        border: 1px solid #fecaca;
    }

    .issue-invalid_format {
        background-color: #fff7ed;
        color: #ea580c;
        border: 1px solid #fed7aa;
    }

    .issue-ambiguous_date {
        background-color: #fefce8;
        color: #ca8a04;
        border: 1px solid #fef08a;
    }

    .issue-not_numeric {
        background-color: #faf5ff;
        color: #9333ea;
        border: 1px solid #e9d5ff;
    }

    .issue-invalid_email {
        background-color: #eff6ff;
        color: #2563eb;
        border: 1px solid #bfdbfe;
    }

    /* Anomaly Card */
    .anomaly-card {
        background: white;
        border-left: 4px solid #f59e0b;
        border-radius: 8px;
        padding: 1rem;
        margin-bottom: 0.75rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }

    /* Code Block */
    .code-block {
        background: #1e293b;
        color: #10b981;
        padding: 1rem;
        border-radius: 8px;
        font-family: 'Courier New', monospace;
        font-size: 0.875rem;
        overflow-x: auto;
    }
</style>
""", unsafe_allow_html=True)


# ========== Core Functions ==========

class FieldTypeDetector:
    """AIé©±åŠ¨çš„å­—æ®µç±»å‹æ£€æµ‹å¼•æ“"""

    @staticmethod
    def detect_type(series):
        """è‡ªåŠ¨æ£€æµ‹å­—æ®µç±»å‹"""
        # ç§»é™¤ç©ºå€¼
        non_null = series.dropna()
        if len(non_null) == 0:
            return 'text'

        # æ•°å­—æ£€æµ‹
        numeric_count = pd.to_numeric(non_null, errors='coerce').notna().sum()
        if numeric_count / len(non_null) > 0.8:
            return 'number'

        # æ—¥æœŸæ£€æµ‹
        date_patterns = [
            r'^\d{4}[-/]\d{1,2}[-/]\d{1,2}$',
            r'^\d{1,2}[-/]\d{1,2}[-/]\d{4}$',
            r'^\d{4}\.\d{1,2}\.\d{1,2}$'
        ]
        date_count = sum(
            non_null.astype(str).str.match(pattern).sum()
            for pattern in date_patterns
        )
        if date_count / len(non_null) > 0.7:
            return 'date'

        # é‚®ç®±æ£€æµ‹
        if 'email' in series.name.lower() or 'mail' in series.name.lower():
            return 'email'

            # é‚®ç®±æ£€æµ‹ï¼šå¢åŠ å¯¹ # å·çš„å®½å®¹åº¦ï¼Œç”¨äºåˆæ¬¡è¯†åˆ«
            # åªè¦åŒ…å« "å­—æ¯ + @æˆ–# + å­—æ¯" å°±åˆæ­¥è®¤å®šä¸ºé‚®ç®±
        email_like_pattern = r'[a-zA-Z0-9._%+-]+[@#][a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        email_hits = non_null.str.match(email_like_pattern).sum()
        if email_hits / len(non_null) > 0.6:  # åªè¦æœ‰ 60% åƒé‚®ç®±å°±è®¤å®šæ˜¯
            return 'email'

        # å¸ƒå°”æ£€æµ‹
        bool_values = ['true', 'false', 'yes', 'no', '1', '0', 'y', 'n', 'T', 'F']
        bool_count = non_null.astype(str).str.lower().isin(bool_values).sum()
        if bool_count / len(non_null) > 0.8:
            return 'boolean'

        return 'text'


# class DataCleaner:
#     """é«˜çº§æ•°æ®æ¸…æ´—å¼•æ“"""
#
#     def __init__(self):
#         self.cleaning_log = []
#         self.rules = {
#             'age': {'min': 0, 'max': 120},
#             'salary': {'min': 0, 'max': 10000000},
#             'price': {'min': 0, 'max': 1000000},
#             'quantity': {'min': 0, 'max': 100000}
#         }
#
#     def clean_date(self, value, row_idx, col_name):
#         """å¤šæ ¼å¼æ—¥æœŸæ¸…æ´—ï¼ˆå«æ­§ä¹‰æ£€æµ‹ï¼‰"""
#         if pd.isna(value):
#             return value
#
#         str_val = str(value).strip()
#
#         # æ ¼å¼1: YYYY-MM-DD æˆ– YYYY/MM/DD
#         match = re.match(r'^(\d{4})[-/](\d{1,2})[-/](\d{1,2})$', str_val)
#         if match:
#             year, month, day = match.groups()
#             return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
#
#         # æ ¼å¼2: DD-MM-YYYY æˆ– MM-DD-YYYY (æ­§ä¹‰æ£€æµ‹)
#         match = re.match(r'^(\d{1,2})[-/](\d{1,2})[-/](\d{4})$', str_val)
#         if match:
#             p1, p2, year = match.groups()
#             if int(p1) <= 12 and int(p2) <= 12:
#                 # æ­§ä¹‰æ—¥æœŸ
#                 self.cleaning_log.append({
#                     'row': row_idx + 1,
#                     'column': col_name,
#                     'raw': value,
#                     'cleaned': f"{year}-{p1.zfill(2)}-{p2.zfill(2)}",
#                     'issue': 'ambiguous_date',
#                     'rule': None,
#                     'hint': f'å¯èƒ½æ˜¯{p1}æœˆ{p2}æ—¥ æˆ– {p2}æœˆ{p1}æ—¥'
#                 })
#                 return f"{year}-{p1.zfill(2)}-{p2.zfill(2)}"
#             else:
#                 # æ˜ç¡®çš„æ—¥æœŸ
#                 month = p1 if int(p1) <= 12 else p2
#                 day = p2 if int(p1) <= 12 else p1
#                 return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
#
#         # æ ¼å¼3: YYYY.MM.DD
#         match = re.match(r'^(\d{4})\.(\d{1,2})\.(\d{1,2})$', str_val)
#         if match:
#             year, month, day = match.groups()
#             return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
#
#         # æ— æ³•è§£æ
#         self.cleaning_log.append({
#             'row': row_idx + 1,
#             'column': col_name,
#             'raw': value,
#             'cleaned': None,
#             'issue': 'invalid_format',
#             'rule': 'valid_date_format',
#             'hint': 'æ”¯æŒæ ¼å¼: YYYY-MM-DD, DD/MM/YYYY, YYYY.MM.DD'
#         })
#         return value
#
#     def clean_numeric(self, value, row_idx, col_name):
#         """æ•°å€¼æ¸…æ´—ï¼ˆå«èŒƒå›´æ£€æµ‹ï¼‰"""
#         try:
#             num = float(value)
#         except (ValueError, TypeError):
#             self.cleaning_log.append({
#                 'row': row_idx + 1,
#                 'column': col_name,
#                 'raw': value,
#                 'cleaned': None,
#                 'issue': 'not_numeric',
#                 'rule': 'numeric_type',
#                 'hint': None
#             })
#             return value
#
#         # æ£€æŸ¥èŒƒå›´è§„åˆ™
#         col_lower = col_name.lower()
#         for rule_key, rule_val in self.rules.items():
#             if rule_key in col_lower:
#                 if 'min' in rule_val and num < rule_val['min']:
#                     self.cleaning_log.append({
    #                     'row': row_idx + 1,
    #                     'column': col_name,
    #                     'raw': value,
    #                     'cleaned': None,
    #                     'issue': 'out_of_range',
    #                     'rule': f"{col_name} >= {rule_val['min']}",
    #                     'hint': None
    #                 })
    #                 return None
    #
    #             if 'max' in rule_val and num > rule_val['max']:
    #                 self.cleaning_log.append({
    #                     'row': row_idx + 1,
    #                     'column': col_name,
    #                     'raw': value,
    #                     'cleaned': None,
    #                     'issue': 'out_of_range',
    #                     'rule': f"{col_name} <= {rule_val['max']}",
    #                     'hint': None
    #                 })
    #                 return None
    #
    #     return num
    #
    # def clean_email(self, value, row_idx, col_name):
    #     """é‚®ç®±æ¸…æ´—"""
    #     if pd.isna(value):
    #         return value
    #
    #     email = str(value).strip().lower()
    #     # ä¿®å¤å¸¸è§é”™è¯¯
    #     email = email.replace('#', '@').replace('ï¼ ', '@')
    #
    #     # éªŒè¯æ ¼å¼
    #     email_pattern = r'^[^\s@]+@[^\s@]+\.[^\s@]+$'
    #     if not re.match(email_pattern, email):
    #         self.cleaning_log.append({
    #             'row': row_idx + 1,
    #             'column': col_name,
    #             'raw': value,
    #             'cleaned': email,
    #             'issue': 'invalid_email',
    #             'rule': 'valid_email_format',
    #             'hint': 'ç¼ºå°‘@æˆ–åŸŸåä¸å®Œæ•´'
    #         })
    #
    #     return email
    #
    # def clean_dataframe(self, df, field_types):
    #     """æ¸…æ´—æ•´ä¸ªDataFrame"""
    #     self.cleaning_log = []  # é‡ç½®æ—¥å¿—
    #     df_cleaned = df.copy()
    #     df_original = df.copy()  # ä¿å­˜åŸå§‹æ•°æ®
    #
    #     for col in df.columns:
    #         if col not in field_types:
    #             continue
    #
    #         field_type = field_types[col]
    #
    #         if field_type == 'date':
    #             df_cleaned[col] = [
    #                 self.clean_date(val, idx, col)
    #                 for idx, val in enumerate(df[col])
    #             ]
    #
    #         elif field_type == 'number':
    #             df_cleaned[col] = [
    #                 self.clean_numeric(val, idx, col)
    #                 for idx, val in enumerate(df[col])
    #             ]
    #
    #         elif field_type == 'email':
    #             df_cleaned[col] = [
    #                 self.clean_email(val, idx, col)
    #                 for idx, val in enumerate(df[col])
    #             ]
    #
    #     return df_cleaned, df_original, self.cleaning_log
                    #æ›¿æ¢å‰classdatacleançš„ç‰ˆæœ¬

class DataCleaner:
    """é«˜çº§æ•°æ®æ¸…æ´—å¼•æ“ (å…¨åŠŸèƒ½åˆå¹¶ç‰ˆ)"""

    def __init__(self):
        self.cleaning_log = []
        # 1. ä¿ç•™ä½ åŸå§‹å®šä¹‰çš„ä¸šåŠ¡è§„åˆ™
        self.rules = {
            'age': {'min': 0, 'max': 120},
            'salary': {'min': 0, 'max': 10000000},
            'price': {'min': 0, 'max': 1000000},
            'quantity': {'min': 0, 'max': 100000}
        }

    def clean_date(self, value, row_idx, col_name):
        """å¤šæ ¼å¼ + è‡ªç„¶è¯­è¨€ + æ­§ä¹‰æ£€æµ‹"""
        if pd.isna(value): return value
        str_val = str(value).strip().lower()

        # --- A. æ–°å¢ï¼šå¤„ç†è‡ªç„¶è¯­è¨€ (yesterday) ---
        from datetime import timedelta
        if str_val == 'yesterday':
            return (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        if str_val == 'today':
            return datetime.now().strftime('%Y-%m-%d')

        # --- B. ä¿ç•™ï¼šåŸæœ‰æ­£åˆ™åŒ¹é…é€»è¾‘ ---
        # æ ¼å¼1: YYYY-MM-DD æˆ– YYYY/MM/DD
        match_ymd = re.match(r'^(\d{4})[-/](\d{1,2})[-/](\d{1,2})$', str_val)
        if match_ymd:
            y, m, d = match_ymd.groups()
            return f"{y}-{m.zfill(2)}-{d.zfill(2)}"

        # æ ¼å¼2: DD-MM-YYYY æˆ– MM-DD-YYYY (å«åŸæœ‰çš„æ­§ä¹‰æ£€æµ‹)
        match_dmy = re.match(r'^(\d{1,2})[-/](\d{1,2})[-/](\d{4})$', str_val)
        if match_dmy:
            p1, p2, year = match_dmy.groups()
            if int(p1) <= 12 and int(p2) <= 12:
                self.cleaning_log.append({
                    'row': row_idx + 1, 'column': col_name, 'raw': value,
                    'cleaned': f"{year}-{p1.zfill(2)}-{p2.zfill(2)}",
                    'issue': 'ambiguous_date', 'rule': None,
                    'hint': f'å¯èƒ½æ˜¯{p1}æœˆ{p2}æ—¥ æˆ– {p2}æœˆ{p1}æ—¥'
                })
                return f"{year}-{p1.zfill(2)}-{p2.zfill(2)}"
            else:
                month = p1 if int(p1) <= 12 else p2
                day = p2 if int(p1) <= 12 else p1
                return f"{year}-{month.zfill(2)}-{day.zfill(2)}"

        # æ ¼å¼3: YYYY.MM.DD (åŸæœ‰çš„ç‚¹å·åˆ†éš”)
        match_dot = re.match(r'^(\d{4})\.(\d{1,2})\.(\d{1,2})$', str_val)
        if match_dot:
            y, m, d = match_dot.groups()
            return f"{y}-{m.zfill(2)}-{d.zfill(2)}"

        # æ— æ³•è§£æ
        self.cleaning_log.append({
            'row': row_idx + 1, 'column': col_name, 'raw': value,
            'cleaned': None, 'issue': 'invalid_format', 'rule': 'valid_date_format',
            'hint': 'æ”¯æŒæ ¼å¼: YYYY-MM-DD, DD/MM/YYYY, YYYY.MM.DD, yesterday'
        })
        return value

    def clean_numeric(self, value, row_idx, col_name):
        if pd.isna(value) or str(value).strip() == "":
            return None

        raw_str = str(value).strip()
        str_val = raw_str.lower()

        # 1. è¯†åˆ«æ— æ•ˆå ä½ç¬¦
        null_keywords = ['unknown', 'not a number', 'not_a_number', 'nan', 'n/a', '?', 'none', 'null', '-', 'undefined']
        if str_val in null_keywords:
            self.add_log(row_idx, col_name, raw_str, None, 'placeholder_value', f'è¯†åˆ«ä¸ºæ— æ•ˆå ä½ç¬¦: {raw_str}')
            return None

        # 2. é¢„å¤„ç†ï¼šç§»é™¤è´§å¸ç¬¦å·å’Œåƒåˆ†ä½é€—å· (è®© $7,000 å˜æˆ 7000)
        temp_val = str_val.replace('$', '').replace('ï¿¥', '').replace(',', '')

        # 3. æå–æ•°å­—éƒ¨åˆ†
        import re
        clean_num_match = re.search(r'[-+]?\d*\.?\d+', temp_val)

        try:
            if not clean_num_match:
                raise ValueError
            num = float(clean_num_match.group())
        except (ValueError, TypeError):
            self.add_log(row_idx, col_name, raw_str, None, 'not_numeric', 'æ— æ³•è§£æä¸ºæ•°å€¼')
            return None

        # 4. èŒƒå›´æ£€æŸ¥ (æ ¹æ®ä½ çš„ rules é…ç½®)
        col_lower = col_name.lower()
        if hasattr(self, 'rules'):
            for rule_key, rule_val in self.rules.items():
                if rule_key in col_lower:
                    if 'min' in rule_val and num < rule_val['min']:
                        self.add_log(row_idx, col_name, raw_str, None, 'out_of_range', 'æ•°å€¼ä½äºæœ€å°å€¼')
                        return None
                    if 'max' in rule_val and num > rule_val['max']:
                        self.add_log(row_idx, col_name, raw_str, None, 'out_of_range', 'æ•°å€¼è¶…å‡ºæœ€å¤§å€¼')
                        return None

        return num

    def clean_email(self, value, row_idx, col_name):
        """é‚®ç®±æ¸…æ´— (å« # è‡ªåŠ¨ä¿®å¤)"""
        if pd.isna(value): return value
        email = str(value).strip().lower()

        # --- æ–°å¢ï¼šä¿®å¤ç¬¦å·é”™è¯¯ ---
        email = email.replace('#', '@').replace('ï¼ ', '@')

        # --- ä¿ç•™ï¼šåŸæœ‰æ ¼å¼éªŒè¯ ---
        email_pattern = r'^[^\s@]+@[^\s@]+\.[^\s@]+$'
        if not re.match(email_pattern, email):
            self.cleaning_log.append({
                'row': row_idx + 1, 'column': col_name, 'raw': value,
                'cleaned': email, 'issue': 'invalid_email',
                'rule': 'valid_email_format', 'hint': 'ç¼ºå°‘@æˆ–åŸŸååç¼€ä¸å®Œæ•´'
            })
        return email

    def clean_dataframe(self, df, field_types):
        """æ‰§è¡Œæ¸…æ´—ç®¡é“ (ä¿æŒåŸç»“æ„)"""
        self.cleaning_log = []
        df_cleaned = df.copy()
        df_original = df.copy()

        for col in df.columns:
            if col not in field_types:
                continue

            f_type = field_types[col]

            if f_type == 'number':
            # 1. ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ï¼Œä¼ å…¥æ­£ç¡®çš„è¡Œç´¢å¼• i
            cleaned_list = [
                self.clean_numeric(val, i, col)
                for i, val in enumerate(df[col])
            ]

            # 2. è½¬æ¢ä¸º Series
            cleaned_series = pd.Series(cleaned_list, index=df.index)

            # 3. ã€æ ¸å¿ƒä¿®å¤ã€‘å¼ºåˆ¶è½¬æ¢å¹¶èµ‹å€¼
            # è¿™ä¸€æ­¥ä¼šç¡®ä¿ $7000 å˜æˆ 7000.0ï¼Œä¸”æ•´åˆ— dtype å˜ä¸º float64
            df_cleaned[col] = pd.to_numeric(cleaned_series, errors='coerce')

            elif f_type == 'email':
                # å¤„ç† Email
                df_cleaned[col] = df[col].apply(lambda x: self.clean_email(x, 0, col))

            elif f_type == 'date':
                # å¤„ç†æ—¥æœŸ
                df_cleaned[col] = df[col].apply(lambda x: self.clean_date(x, 0, col))

        # --- æœ€ç»ˆå…œåº•ï¼šå¦‚æœåˆ—åé‡Œæœ‰ salaryï¼Œå†æ¬¡ç¡®ä¿å®ƒæ˜¯ float ---
        for col in df_cleaned.columns:
            if 'salary' in col.lower():
                df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')

        return df_cleaned, df_original, self.cleaning_log






# ========== Session State Initialization ==========
if 'data' not in st.session_state:
    st.session_state.data = None
if 'data_cleaned' not in st.session_state:
    st.session_state.data_cleaned = None
if 'data_original' not in st.session_state:
    st.session_state.data_original = None
if 'field_types' not in st.session_state:
    st.session_state.field_types = {}
if 'cleaning_log' not in st.session_state:
    st.session_state.cleaning_log = []
if 'show_original' not in st.session_state:
    st.session_state.show_original = False


# ========== Main App ==========

def main():
    # Hero Section
    st.markdown("""
        <div class="hero-banner">
            <div class="hero-title">ğŸ”¬ Advanced Data Refinery</div>
            <div class="hero-subtitle">
                AI-Powered Data Cleaning Engine with Smart Anomaly Detection & Structured Logging
            </div>
        </div>
    """, unsafe_allow_html=True)

    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ Configuration")

        uploaded_file = st.file_uploader(
            "Upload Dataset",
            type=['csv', 'xlsx', 'xls'],
            help="æ”¯æŒCSVå’ŒExcelæ ¼å¼"
        )

        if uploaded_file:
            try:
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)

                st.session_state.data = df
                st.success(f"âœ… Loaded {len(df)} rows Ã— {len(df.columns)} columns")

                # è‡ªåŠ¨æ£€æµ‹å­—æ®µç±»å‹
                if st.button("ğŸ¤– Auto-Detect Field Types", use_container_width=True):
                    detector = FieldTypeDetector()
                    types = {}
                    for col in df.columns:
                        types[col] = detector.detect_type(df[col])
                    st.session_state.field_types = types
                    st.success("âœ… Field types detected!")
                    st.rerun()

            except Exception as e:
                st.error(f"Error loading file: {e}")

        st.markdown("---")

        # ä½¿ç”¨ç¤ºä¾‹æ•°æ®
        if st.button("ğŸ“Š Load Sample Data", use_container_width=True):
            sample_data = pd.DataFrame({
                'id': [1, 2, 3, 4, 5],
                'name': ['Zhang San', 'Li Si', 'Wang Wu', 'Zhao Liu', 'Qian Qi'],
                'age': [25, 30, 150, 'invalid', 28],
                'email': ['zhang#example.com', 'lisi@example', 'wang@test.com', 'zhao@company.cn', 'qian@tech.io'],
                'date': ['2024-01-15', '01/02/2024', '2024.03.20', '2024-04-01', 'not-a-date'],
                'salary': [5000, 6000, -1000, 8000, 7500]
            })
            st.session_state.data = sample_data

            # è‡ªåŠ¨æ£€æµ‹ç±»å‹
            detector = FieldTypeDetector()
            types = {}
            for col in sample_data.columns:
                if col != 'id':
                    types[col] = detector.detect_type(sample_data[col])
            st.session_state.field_types = types
            st.success("âœ… Sample data loaded!")
            st.rerun()

        st.markdown("---")
        st.markdown("### About")
        st.info(
            "**Advanced Data Refinery v2.0**\n\n"
            "æ¯”OpenRefineæ›´å…ˆè¿›:\n"
            "â€¢ AIè‡ªåŠ¨ç±»å‹è¯†åˆ«\n"
            "â€¢ æ—¥æœŸæ­§ä¹‰æ£€æµ‹\n"
            "â€¢ åŸå§‹å€¼ä¿ç•™\n"
            "â€¢ ç»“æ„åŒ–æ—¥å¿—"
        )

    # Main Content
    if st.session_state.data is None:
        st.info("ğŸ‘ˆ è¯·ä»ä¾§è¾¹æ ä¸Šä¼ æ•°æ®æˆ–åŠ è½½ç¤ºä¾‹æ•°æ®")
        return

    df = st.session_state.data

    # Stats Bar
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.markdown("""
            <div class="stat-card">
                <div class="stat-label">Total Records</div>
                <div class="stat-value">{}</div>
            </div>
        """.format(len(df)), unsafe_allow_html=True)

    with col2:
        st.markdown("""
            <div class="stat-card">
                <div class="stat-label">Fields Detected</div>
                <div class="stat-value">{}</div>
            </div>
        """.format(len(st.session_state.field_types)), unsafe_allow_html=True)

    with col3:
        issues = len(st.session_state.cleaning_log)
        st.markdown("""
            <div class="stat-card" style="border-left-color: #f59e0b;">
                <div class="stat-label">Issues Found</div>
                <div class="stat-value" style="color: #f59e0b;">{}</div>
            </div>
        """.format(issues), unsafe_allow_html=True)

    with col4:
        clean_rate = 100 if issues == 0 else max(0,
                                                 100 - (issues / (len(df) * len(st.session_state.field_types)) * 100))
        st.markdown("""
            <div class="stat-card" style="border-left-color: #10b981;">
                <div class="stat-label">Clean Rate</div>
                <div class="stat-value" style="color: #10b981;">{:.0f}%</div>
            </div>
        """.format(clean_rate), unsafe_allow_html=True)

    st.markdown("<br>", unsafe_allow_html=True)

    # Tabs
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“Š Data View",
        "âš™ï¸ Field Types",
        "ğŸš¨ Anomaly Panel",
        "ğŸ“‹ Cleaning Logs"
    ])

    # Tab 1: Data View
    with tab1:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.subheader("Data Preview")
        with col2:
            view_mode = st.radio(
                "View Mode",
                ["Cleaned", "Original"],
                horizontal=True,
                key="view_mode"
            )

        display_df = st.session_state.data_original if view_mode == "Original" and st.session_state.data_original is not None else (
            st.session_state.data_cleaned if st.session_state.data_cleaned is not None else df)

        st.dataframe(
            display_df,
            use_container_width=True,
            height=400
        )

        # ä¸‹è½½æ¸…æ´—åæ•°æ®
        if st.session_state.data_cleaned is not None:
            csv = st.session_state.data_cleaned.to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ Download Cleaned Data (CSV)",
                data=csv,
                file_name=f"cleaned_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )

    # Tab 2: Field Types
    with tab2:
        st.subheader("Auto-Detected Field Types")

        if not st.session_state.field_types:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ ç‚¹å‡» 'Auto-Detect Field Types'")
        else:
            type_icons = {
                'text': 'ğŸ“',
                'number': 'ğŸ”¢',
                'date': 'ğŸ“…',
                'email': 'ğŸ“§',
                'boolean': 'âœ“'
            }

            cols = st.columns(3)
            for idx, (field, ftype) in enumerate(st.session_state.field_types.items()):
                with cols[idx % 3]:
                    icon = type_icons.get(ftype, 'â“')
                    st.markdown(f"""
                        <div style="background: white; padding: 1rem; border-radius: 8px; border-left: 4px solid #3b82f6; margin-bottom: 1rem;">
                            <div style="font-size: 1.5rem; margin-bottom: 0.5rem;">{icon}</div>
                            <div style="font-weight: 600; color: #1e293b;">{field}</div>
                            <div style="font-size: 0.75rem; color: #64748b; text-transform: uppercase;">{ftype}</div>
                        </div>
                    """, unsafe_allow_html=True)

            st.markdown("---")

            # Cleaning Rules Configuration
            st.subheader("âš™ï¸ Cleaning Rules")
            st.info("ä¸ºæ•°å€¼å­—æ®µé…ç½®éªŒè¯è§„åˆ™ï¼ˆå¯é€‰ï¼‰")

            numeric_fields = [f for f, t in st.session_state.field_types.items() if t == 'number']

            if numeric_fields:
                for field in numeric_fields:
                    with st.expander(f"ğŸ”¢ {field} - Range Rules"):
                        col1, col2 = st.columns(2)
                        with col1:
                            min_val = st.number_input(
                                f"Minimum value",
                                value=0.0,
                                key=f"min_{field}"
                            )
                        with col2:
                            max_val = st.number_input(
                                f"Maximum value",
                                value=1000000.0,
                                key=f"max_{field}"
                            )

            # Start Cleaning Button
            if st.button("ğŸš€ Start Data Cleaning Pipeline", type="primary", use_container_width=True):
                with st.spinner("ğŸ”„ Processing data..."):
                    cleaner = DataCleaner()
                    df_cleaned, df_original, logs = cleaner.clean_dataframe(
                        df,
                        st.session_state.field_types
                    )
                    st.session_state.data_cleaned = df_cleaned
                    st.session_state.data_original = df_original
                    st.session_state.cleaning_log = logs
                    st.success(f"âœ… Cleaning complete! Found {len(logs)} issues.")
                    st.rerun()

    # Tab 3: Anomaly Panel
    with tab3:
        if not st.session_state.cleaning_log:
            st.info("â„¹ï¸ æ²¡æœ‰æ£€æµ‹åˆ°å¼‚å¸¸ã€‚è¯·å…ˆè¿è¡Œæ•°æ®æ¸…æ´—ã€‚")
        else:
            st.subheader("ğŸš¨ Anomaly Detection Panel")

            logs = st.session_state.cleaning_log

            # Issue Type Statistics
            issue_counts = {}
            for log in logs:
                issue = log['issue']
                issue_counts[issue] = issue_counts.get(issue, 0) + 1

            issue_labels = {
                'out_of_range': 'è¶…å‡ºèŒƒå›´',
                'invalid_format': 'æ ¼å¼é”™è¯¯',
                'ambiguous_date': 'æ—¥æœŸæ­§ä¹‰',
                'not_numeric': 'éæ•°å€¼',
                'invalid_email': 'é‚®ç®±æ ¼å¼'
            }

            st.markdown("#### ğŸ“Š Issue Statistics")
            cols = st.columns(len(issue_counts))
            for idx, (issue, count) in enumerate(issue_counts.items()):
                with cols[idx]:
                    st.markdown(f"""
                        <div style="background: white; padding: 1rem; border-radius: 8px; text-align: center; border: 2px solid #e2e8f0;">
                            <div style="font-size: 2rem; font-weight: 700; color: #1e293b;">{count}</div>
                            <div style="font-size: 0.75rem; color: #64748b;">{issue_labels.get(issue, issue)}</div>
                        </div>
                    """, unsafe_allow_html=True)

            st.markdown("---")

            # Filters
            col1, col2, col3 = st.columns([2, 2, 1])
            with col1:
                filter_column = st.selectbox(
                    "Filter by Column",
                    ["All"] + list(set(log['column'] for log in logs))
                )
            with col2:
                filter_issue = st.selectbox(
                    "Filter by Issue Type",
                    ["All"] + list(issue_counts.keys())
                )
            with col3:
                if st.button("ğŸ“¥ Export", use_container_width=True):
                    json_data = json.dumps(logs, indent=2, ensure_ascii=False)
                    st.download_button(
                        label="Download JSON",
                        data=json_data,
                        file_name=f"anomalies_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )

            # Filter logs
            filtered_logs = logs
            if filter_column != "All":
                filtered_logs = [l for l in filtered_logs if l['column'] == filter_column]
            if filter_issue != "All":
                filtered_logs = [l for l in filtered_logs if l['issue'] == filter_issue]

            st.markdown(f"#### Found {len(filtered_logs)} anomalies")

            # Display anomalies
            for log in filtered_logs:
                issue_class = f"issue-{log['issue']}"
                st.markdown(f"""
                    <div class="anomaly-card">
                        <div style="display: flex; justify-content: space-between; align-items: start; margin-bottom: 0.75rem;">
                            <div>
                                <strong>Row {log['row']}</strong> â†’ <strong>{log['column']}</strong>
                                <span class="issue-badge {issue_class}">{issue_labels.get(log['issue'], log['issue'])}</span>
                            </div>
                        </div>
                        <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 1rem; font-size: 0.875rem;">
                            <div>
                                <div style="color: #64748b; font-size: 0.75rem; margin-bottom: 0.25rem;">Original</div>
                                <code style="background: #f1f5f9; padding: 0.25rem 0.5rem; border-radius: 4px;">{log['raw']}</code>
                            </div>
                            <div>
                                <div style="color: #64748b; font-size: 0.75rem; margin-bottom: 0.25rem;">Cleaned</div>
                                <code style="background: #dcfce7; padding: 0.25rem 0.5rem; border-radius: 4px;">{log['cleaned'] if log['cleaned'] is not None else 'null'}</code>
                            </div>
                            {f'''<div>
                                <div style="color: #64748b; font-size: 0.75rem; margin-bottom: 0.25rem;">Rule</div>
                                <code style="background: #dbeafe; padding: 0.25rem 0.5rem; border-radius: 4px; font-size: 0.7rem;">{log['rule']}</code>
                            </div>''' if log['rule'] else ''}
                        </div>
                        {f'<div style="margin-top: 0.75rem; background: #fef3c7; padding: 0.5rem; border-radius: 4px; font-size: 0.8rem; color: #92400e;">ğŸ’¡ {log["hint"]}</div>' if log.get('hint') else ''}
                    </div>
                """, unsafe_allow_html=True)

    ## Tab 4: Cleaning Logs
    with tab4:
        st.subheader("ğŸ“‹ Structured Cleaning Logs (JSON)")

        if not st.session_state.cleaning_log:
            st.info("â„¹ï¸ æ²¡æœ‰æ¸…æ´—æ—¥å¿—ã€‚è¯·å…ˆè¿è¡Œæ•°æ®æ¸…æ´—ã€‚")
        else:
            col1, col2 = st.columns([4, 1])

            json_data = json.dumps(st.session_state.cleaning_log, indent=2, ensure_ascii=False)

            with col2:
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ JSON",
                    data=json_data,
                    file_name=f"cleaning_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True
                )

            # Display JSON
            st.markdown('<div class="code-block">', unsafe_allow_html=True)
            st.json(st.session_state.cleaning_log)
            st.markdown('</div>', unsafe_allow_html=True)

            # Log Summary
            st.markdown("---")
            st.markdown("#### ğŸ“Š Log Summary")

            summary_data = {
                'Total Issues': len(st.session_state.cleaning_log),
                'Affected Rows': len(set(log['row'] for log in st.session_state.cleaning_log)),
                'Affected Columns': len(set(log['column'] for log in st.session_state.cleaning_log)),
                'Issue Types': len(set(log['issue'] for log in st.session_state.cleaning_log))
            }

            cols = st.columns(4)
            for idx, (key, value) in enumerate(summary_data.items()):
                with cols[idx]:
                    st.metric(key, value)

# ç¡®ä¿æ–‡ä»¶æœ«å°¾æœ‰è¿™ä¸€è¡Œæ¥å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    main()